from fastapi import FastAPI, UploadFile, Form
import torch
import os
from model import DogSoundClassifierV2
from server.preprocess import preprocess_audio
from utils.sender import send_result_to_backend
from server.barknet_detector import detect_bark as is_dog_bark

app = FastAPI()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = DogSoundClassifierV2().to(device)
model.load_state_dict(torch.load("dog_sound_classifier_v2.pth", map_location=device))
model.eval()

class_names = ["Bark", "Growl", "Grunt"]

@app.post("/ai/predict")
async def predict(file: UploadFile, device_id: str = Form(...)):
    print("ğŸ”„ [DEBUG] Step 1: Audio file saving started")

    # 1. ì˜¤ë””ì˜¤ ì €ì¥
    with open("temp.wav", "wb") as f:
        f.write(await file.read())

    print("ğŸ”„ [DEBUG] Step 2: Audio file saved")

    # 2. ê°•ì•„ì§€ ì†Œë¦¬ ê°ì§€
    is_bark, _ = is_dog_bark("temp.wav")
    if not is_bark:
        print("ğŸ”¹ [DEBUG] No dog bark detected")
        return {"result": "No dog bark detected"}

    print("ğŸ”„ [DEBUG] Step 3: Bark detected")

    # 3. ì „ì²˜ë¦¬
    mfcc = preprocess_audio("temp.wav", device)
    print("ğŸ”„ [DEBUG] Step 4: Preprocessing completed")

    # 4. ë¶„ë¥˜
    try:
        with torch.no_grad():
            outputs = model(mfcc)
            pred = torch.argmax(outputs, dim=1).item()
            confidence = torch.softmax(outputs, dim=1).max().item()
        result = class_names[pred]
        print(f"ğŸ”„ [DEBUG] Step 5: Prediction done - {result} with confidence {confidence}")
    except Exception as e:
        print(f"ğŸ”´ [ERROR] Model inference failed: {e}")
        return {"result": "Model inference failed"}

    # 5. ê²°ê³¼ ì „ì†¡
    print(f"ğŸ”„ [DEBUG] Step 6: Sending to Flask - {result}")
    from utils.sender import send_result_to_backend
    send_result_to_backend(device_id, result, confidence)

    print("ğŸ”„ [DEBUG] Step 7: sender.py call completed")

    return {"result": result}
